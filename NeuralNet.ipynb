{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_load = pd.read_pickle(\"data/earlyAprilDataEnriched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_load = pd.read_pickle(\"data/lateAprilDataEnriched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>Lpep_dropoff_datetime</th>\n",
       "      <th>Store_and_fwd_flag</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>Pickup_longitude</th>\n",
       "      <th>Pickup_latitude</th>\n",
       "      <th>Dropoff_longitude</th>\n",
       "      <th>Dropoff_latitude</th>\n",
       "      <th>Passenger_count</th>\n",
       "      <th>Trip_type</th>\n",
       "      <th>VincentyMiles</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>NewSnow</th>\n",
       "      <th>trip_length_seconds</th>\n",
       "      <th>trip_length_minutes_rounded</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>dropoff_minute</th>\n",
       "      <th>dropoff_hour</th>\n",
       "      <th>dropoff_day</th>\n",
       "      <th>dropoff_weekday</th>\n",
       "      <th>pickup_sunrise</th>\n",
       "      <th>pickup_sunset</th>\n",
       "      <th>dropoff_sunrise</th>\n",
       "      <th>dropoff_sunset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4532400</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:02:03</td>\n",
       "      <td>2016-04-01 00:05:53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.991180</td>\n",
       "      <td>40.685608</td>\n",
       "      <td>-73.984116</td>\n",
       "      <td>40.695980</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.806173</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532401</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:01:31</td>\n",
       "      <td>2016-04-01 00:05:55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.844292</td>\n",
       "      <td>40.721432</td>\n",
       "      <td>-73.850441</td>\n",
       "      <td>40.724144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373149</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532402</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:00:57</td>\n",
       "      <td>2016-04-01 00:07:36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.944008</td>\n",
       "      <td>40.714539</td>\n",
       "      <td>-73.938705</td>\n",
       "      <td>40.724926</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.768917</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532403</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:01:22</td>\n",
       "      <td>2016-04-01 00:06:12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.952789</td>\n",
       "      <td>40.810749</td>\n",
       "      <td>-73.963509</td>\n",
       "      <td>40.796486</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.133387</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532404</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:00:56</td>\n",
       "      <td>2016-04-01 00:05:25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.991249</td>\n",
       "      <td>40.691433</td>\n",
       "      <td>-73.988762</td>\n",
       "      <td>40.683598</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.556217</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532405</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:00:47</td>\n",
       "      <td>2016-04-01 00:14:49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.968704</td>\n",
       "      <td>40.677856</td>\n",
       "      <td>-73.935036</td>\n",
       "      <td>40.651569</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.533694</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532406</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:00:07</td>\n",
       "      <td>2016-04-01 00:03:41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.957878</td>\n",
       "      <td>40.711040</td>\n",
       "      <td>-73.955887</td>\n",
       "      <td>40.707653</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.256062</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532407</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:00:13</td>\n",
       "      <td>2016-04-01 00:18:43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.960648</td>\n",
       "      <td>40.719345</td>\n",
       "      <td>-73.917854</td>\n",
       "      <td>40.781212</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.823582</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532408</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:00:34</td>\n",
       "      <td>2016-04-01 00:12:19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.984062</td>\n",
       "      <td>40.676144</td>\n",
       "      <td>-74.027718</td>\n",
       "      <td>40.632233</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.800473</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532409</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-01 00:47:13</td>\n",
       "      <td>2016-04-01 00:59:30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.884544</td>\n",
       "      <td>40.755604</td>\n",
       "      <td>-73.856026</td>\n",
       "      <td>40.745335</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.655823</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID lpep_pickup_datetime Lpep_dropoff_datetime  \\\n",
       "4532400         2  2016-04-01 00:02:03   2016-04-01 00:05:53   \n",
       "4532401         2  2016-04-01 00:01:31   2016-04-01 00:05:55   \n",
       "4532402         2  2016-04-01 00:00:57   2016-04-01 00:07:36   \n",
       "4532403         2  2016-04-01 00:01:22   2016-04-01 00:06:12   \n",
       "4532404         2  2016-04-01 00:00:56   2016-04-01 00:05:25   \n",
       "4532405         2  2016-04-01 00:00:47   2016-04-01 00:14:49   \n",
       "4532406         2  2016-04-01 00:00:07   2016-04-01 00:03:41   \n",
       "4532407         2  2016-04-01 00:00:13   2016-04-01 00:18:43   \n",
       "4532408         2  2016-04-01 00:00:34   2016-04-01 00:12:19   \n",
       "4532409         2  2016-04-01 00:47:13   2016-04-01 00:59:30   \n",
       "\n",
       "         Store_and_fwd_flag  RateCodeID  Pickup_longitude  Pickup_latitude  \\\n",
       "4532400                   0           1        -73.991180        40.685608   \n",
       "4532401                   0           1        -73.844292        40.721432   \n",
       "4532402                   0           1        -73.944008        40.714539   \n",
       "4532403                   0           1        -73.952789        40.810749   \n",
       "4532404                   0           1        -73.991249        40.691433   \n",
       "4532405                   0           1        -73.968704        40.677856   \n",
       "4532406                   0           1        -73.957878        40.711040   \n",
       "4532407                   0           1        -73.960648        40.719345   \n",
       "4532408                   0           1        -73.984062        40.676144   \n",
       "4532409                   0           1        -73.884544        40.755604   \n",
       "\n",
       "         Dropoff_longitude  Dropoff_latitude  Passenger_count  Trip_type   \\\n",
       "4532400         -73.984116         40.695980                1         1.0   \n",
       "4532401         -73.850441         40.724144                1         1.0   \n",
       "4532402         -73.938705         40.724926                1         1.0   \n",
       "4532403         -73.963509         40.796486                1         1.0   \n",
       "4532404         -73.988762         40.683598                3         1.0   \n",
       "4532405         -73.935036         40.651569                1         1.0   \n",
       "4532406         -73.955887         40.707653                1         1.0   \n",
       "4532407         -73.917854         40.781212                1         1.0   \n",
       "4532408         -74.027718         40.632233                1         1.0   \n",
       "4532409         -73.856026         40.745335                1         1.0   \n",
       "\n",
       "         VincentyMiles  AvgTemp  Precipitation  NewSnow  trip_length_seconds  \\\n",
       "4532400       0.806173     59.0           0.02      0.0                230.0   \n",
       "4532401       0.373149     59.0           0.02      0.0                264.0   \n",
       "4532402       0.768917     59.0           0.02      0.0                399.0   \n",
       "4532403       1.133387     59.0           0.02      0.0                290.0   \n",
       "4532404       0.556217     59.0           0.02      0.0                269.0   \n",
       "4532405       2.533694     59.0           0.02      0.0                842.0   \n",
       "4532406       0.256062     59.0           0.02      0.0                214.0   \n",
       "4532407       4.823582     59.0           0.02      0.0               1110.0   \n",
       "4532408       3.800473     59.0           0.02      0.0                705.0   \n",
       "4532409       1.655823     59.0           0.02      0.0                737.0   \n",
       "\n",
       "         trip_length_minutes_rounded  pickup_minute  pickup_hour  pickup_day  \\\n",
       "4532400                          4.0              2            0           1   \n",
       "4532401                          4.0              1            0           1   \n",
       "4532402                          7.0              0            0           1   \n",
       "4532403                          5.0              1            0           1   \n",
       "4532404                          4.0              0            0           1   \n",
       "4532405                         14.0              0            0           1   \n",
       "4532406                          4.0              0            0           1   \n",
       "4532407                         18.0              0            0           1   \n",
       "4532408                         12.0              0            0           1   \n",
       "4532409                         12.0             47            0           1   \n",
       "\n",
       "         pickup_weekday  dropoff_minute  dropoff_hour  dropoff_day  \\\n",
       "4532400               4               5             0            1   \n",
       "4532401               4               5             0            1   \n",
       "4532402               4               7             0            1   \n",
       "4532403               4               6             0            1   \n",
       "4532404               4               5             0            1   \n",
       "4532405               4              14             0            1   \n",
       "4532406               4               3             0            1   \n",
       "4532407               4              18             0            1   \n",
       "4532408               4              12             0            1   \n",
       "4532409               4              59             0            1   \n",
       "\n",
       "         dropoff_weekday  pickup_sunrise  pickup_sunset  dropoff_sunrise  \\\n",
       "4532400                4             0.0            0.0              0.0   \n",
       "4532401                4             0.0            0.0              0.0   \n",
       "4532402                4             0.0            0.0              0.0   \n",
       "4532403                4             0.0            0.0              0.0   \n",
       "4532404                4             0.0            0.0              0.0   \n",
       "4532405                4             0.0            0.0              0.0   \n",
       "4532406                4             0.0            0.0              0.0   \n",
       "4532407                4             0.0            0.0              0.0   \n",
       "4532408                4             0.0            0.0              0.0   \n",
       "4532409                4             0.0            0.0              0.0   \n",
       "\n",
       "         dropoff_sunset  \n",
       "4532400             0.0  \n",
       "4532401             0.0  \n",
       "4532402             0.0  \n",
       "4532403             0.0  \n",
       "4532404             0.0  \n",
       "4532405             0.0  \n",
       "4532406             0.0  \n",
       "4532407             0.0  \n",
       "4532408             0.0  \n",
       "4532409             0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_load[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanData(orig_data, get_minutes = False):\n",
    "    label_column = \"trip_length_seconds\"\n",
    "    if get_minutes:\n",
    "        labels = \"trip_length_minutes_rounded\"\n",
    "    labels_array = orig_data[label_column].copy().values\n",
    "    labels = np.reshape(labels_array, (len(labels_array), 1))\n",
    "    clean_data = orig_data.drop(labels = [\"lpep_pickup_datetime\", \"Lpep_dropoff_datetime\", \"trip_length_seconds\", \"trip_length_minutes_rounded\"], axis = 1)\n",
    "    return (clean_data.values, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_with_minutes = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = cleanData(train_data_load, try_with_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data, test_labels = cleanData(test_data_load, try_with_minutes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildNeuralNetAndGetAccuracy(data_for_training, a_train, data_for_testing, a_test):\n",
    "    #Only two layers\n",
    "    batch_size = 300\n",
    "    iterations = 10000\n",
    "    \n",
    "    inputFeatureSize = len(data_for_training[0])\n",
    "    print(\"There are {} features\".format(inputFeatureSize))\n",
    "    hidden_units1 = 25\n",
    "    hidden_units2 = 25\n",
    "    output_size = 1\n",
    "            \n",
    "    input_placeholder = tf.placeholder(tf.float32, shape=(None, inputFeatureSize), name = \"input_placeholder\")\n",
    "    labels_placeholder = tf.placeholder(tf.float32, shape=(None, 1), name = \"labels_placeholder\")\n",
    "    \n",
    "    #remember that we need W of small random values for gradient descent\n",
    "    hiddenLayer1W = tf.Variable(tf.truncated_normal([inputFeatureSize, hidden_units1], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "    hiddenLayer2W = tf.Variable(tf.truncated_normal(shape=(hidden_units1, hidden_units2), stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "    outW = tf.Variable(tf.truncated_normal(shape=(hidden_units2, output_size), stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "\n",
    "    hiddenLayer1b = tf.Variable(tf.truncated_normal([hidden_units1], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "    hiddenLayer2b = tf.Variable(tf.truncated_normal([hidden_units2], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "    outb = tf.Variable(tf.truncated_normal([output_size], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "\n",
    "    hiddenLayer1 = tf.tanh(tf.matmul(input_placeholder, hiddenLayer1W) + hiddenLayer1b)\n",
    "    hiddenLayer2 = tf.tanh(tf.matmul(hiddenLayer1, hiddenLayer2W) + hiddenLayer2b)\n",
    "    p_out = tf.matmul(hiddenLayer2, outW) + outb\n",
    "        \n",
    "#     loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones([len(p_out), 1]))), tf.log(tf.add(a_train, tf.ones([len(a_train), 1])))))))\n",
    "    loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones(tf.stack([tf.shape(p_out)[0], 1])))), tf.log(tf.add(labels_placeholder, tf.ones(tf.stack([tf.shape(labels_placeholder)[0], 1]))))))))\n",
    "\n",
    "    # Other optimizers - https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.25)\n",
    "    \n",
    "    global_step_counter = tf.Variable(0, trainable=False)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step_counter)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        for i in range(0,iterations):\n",
    "            indicies = list(range(0,len(data_for_training)))\n",
    "            shuffle(indicies)\n",
    "            indicies100 = indicies[0:batch_size]\n",
    "            batch_xs = [data_for_training[j] for j in indicies100]\n",
    "            batch_ys = [a_train[j] for j in indicies100]\n",
    "            _, loss_value = sess.run([train_op, loss],\n",
    "                             feed_dict={input_placeholder: batch_xs, labels_placeholder: batch_ys})\n",
    "            if(i%500 == 0):\n",
    "                print(\"Alive and well! {} Loss: {:.2f}\".format(i, loss_value))\n",
    "                saver.save(sess, 'C:\\\\Users\\\\Brittany\\\\Dropbox\\\\School\\\\CMSC678\\\\machine-learning\\\\saved_models\\\\first_model',global_step=i)\n",
    "                \n",
    "        print(\"TRAINED!\")\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        print(p_out.shape())\n",
    "        accuracy = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones(tf.stack([tf.shape(p_out)[0], 1])))), tf.log(tf.add(labels_placeholder, tf.ones(tf.stack([tf.shape(labels_placeholder)[0], 1]))))))))\n",
    "        return accuracy.eval({input_placeholder: data_for_testing, labels_placeholder: a_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25 features\n",
      "Alive and well! 0 Loss: 6.33\n",
      "Alive and well! 500 Loss: 2.22\n",
      "Alive and well! 1000 Loss: 1.82\n",
      "Alive and well! 1500 Loss: 1.65\n",
      "Alive and well! 2000 Loss: 1.63\n",
      "Alive and well! 2500 Loss: 1.46\n",
      "Alive and well! 3000 Loss: 1.44\n",
      "Alive and well! 3500 Loss: 1.38\n",
      "Alive and well! 4000 Loss: 1.23\n",
      "Alive and well! 4500 Loss: 1.22\n",
      "Alive and well! 5000 Loss: 1.22\n",
      "Alive and well! 5500 Loss: 1.19\n",
      "Alive and well! 6000 Loss: 1.13\n",
      "Alive and well! 6500 Loss: 1.11\n",
      "Alive and well! 7000 Loss: 1.10\n",
      "Alive and well! 7500 Loss: 1.10\n",
      "Alive and well! 8000 Loss: 1.01\n",
      "Alive and well! 8500 Loss: 1.02\n",
      "Alive and well! 9000 Loss: 0.96\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Failed to rename: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001.tempstate7531580503328981809 to: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable_1, Variable_2, Variable_3, Variable_4, Variable_5, Variable_6)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-c0fcb84b1cdc>\", line 1, in <module>\n    accResults = buildNeuralNetAndGetAccuracy(train_data, train_labels, test_data, test_labels)\n  File \"<ipython-input-9-d5460c21f919>\", line 37, in buildNeuralNetAndGetAccuracy\n    saver = tf.train.Saver()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1218, in __init__\n    self.build()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 239, in save_op\n    tensors)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1162, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Failed to rename: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001.tempstate7531580503328981809 to: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable_1, Variable_2, Variable_3, Variable_4, Variable_5, Variable_6)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Failed to rename: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001.tempstate7531580503328981809 to: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable_1, Variable_2, Variable_3, Variable_4, Variable_5, Variable_6)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c0fcb84b1cdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccResults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildNeuralNetAndGetAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-d5460c21f919>\u001b[0m in \u001b[0;36mbuildNeuralNetAndGetAccuracy\u001b[1;34m(data_for_training, a_train, data_for_testing, a_test)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m500\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Alive and well! {} Loss: {:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                 \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'C:\\\\Users\\\\Brittany\\\\Dropbox\\\\School\\\\CMSC678\\\\machine-learning\\\\saved_models\\\\first_model'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TRAINED!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[0;32m   1592\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[0;32m   1593\u001b[0m                   save_path))\n\u001b[1;32m-> 1594\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[0;32m   1571\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[0;32m   1572\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1573\u001b[1;33m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[0;32m   1574\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m           self._build_eager(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Failed to rename: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001.tempstate7531580503328981809 to: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable_1, Variable_2, Variable_3, Variable_4, Variable_5, Variable_6)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-c0fcb84b1cdc>\", line 1, in <module>\n    accResults = buildNeuralNetAndGetAccuracy(train_data, train_labels, test_data, test_labels)\n  File \"<ipython-input-9-d5460c21f919>\", line 37, in buildNeuralNetAndGetAccuracy\n    saver = tf.train.Saver()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1218, in __init__\n    self.build()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 239, in save_op\n    tensors)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1162, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Failed to rename: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001.tempstate7531580503328981809 to: C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-9000.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\r\n; Broken pipe\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable_1, Variable_2, Variable_3, Variable_4, Variable_5, Variable_6)]]\n"
     ]
    }
   ],
   "source": [
    "accResults = buildNeuralNetAndGetAccuracy(train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def getNeuralNetAndContinueRunning(data_for_training, a_train, data_for_testing, a_test):\n",
    "#     #Only two layers\n",
    "#     batch_size = 300\n",
    "#     iterations = 1500\n",
    "    \n",
    "#     inputFeatureSize = len(data_for_training[0])\n",
    "#     print(\"There are {} features\".format(inputFeatureSize))\n",
    "#     hidden_units1 = 25\n",
    "#     hidden_units2 = 25\n",
    "#     output_size = 1\n",
    "            \n",
    "#     input_placeholder = tf.placeholder(tf.float32, shape=(None, inputFeatureSize), name = \"input_placeholder\")\n",
    "#     labels_placeholder = tf.placeholder(tf.float32, shape=(None, 1), name = \"labels_placeholder\")\n",
    "    \n",
    "#     #remember that we need W of small random values for gradient descent\n",
    "#     hiddenLayer1W = tf.Variable(tf.truncated_normal([inputFeatureSize, hidden_units1], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "#     hiddenLayer2W = tf.Variable(tf.truncated_normal(shape=(hidden_units1, hidden_units2), stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "#     outW = tf.Variable(tf.truncated_normal(shape=(hidden_units2, output_size), stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "\n",
    "#     hiddenLayer1b = tf.Variable(tf.truncated_normal([hidden_units1], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "#     hiddenLayer2b = tf.Variable(tf.truncated_normal([hidden_units2], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "#     outb = tf.Variable(tf.truncated_normal([output_size], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "\n",
    "#     hiddenLayer1 = tf.tanh(tf.matmul(input_placeholder, hiddenLayer1W) + hiddenLayer1b)\n",
    "#     hiddenLayer2 = tf.tanh(tf.matmul(hiddenLayer1, hiddenLayer2W) + hiddenLayer2b)\n",
    "#     p_out = tf.matmul(hiddenLayer2, outW) + outb\n",
    "        \n",
    "# #     loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones([len(p_out), 1]))), tf.log(tf.add(a_train, tf.ones([len(a_train), 1])))))))\n",
    "#     loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones(tf.stack([tf.shape(p_out)[0], 1])))), tf.log(tf.add(labels_placeholder, tf.ones(tf.stack([tf.shape(labels_placeholder)[0], 1]))))))))\n",
    "\n",
    "#     # Other optimizers - https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(0.25)\n",
    "    \n",
    "#     global_step_counter = tf.Variable(0, trainable=False)\n",
    "#     train_op = optimizer.minimize(loss, global_step=global_step_counter)\n",
    "    \n",
    "#     saver = tf.train.Saver()\n",
    "    \n",
    "#     with tf.Session() as sess:\n",
    "#         saver.restore(sess, \"C:\\\\Users\\\\Brittany\\\\Dropbox\\\\School\\\\CMSC678\\\\machine-learning\\\\saved_models\\\\first_model-8500\")\n",
    "        \n",
    "#         for i in range(0,iterations):\n",
    "#             indicies = list(range(0,len(data_for_training)))\n",
    "#             shuffle(indicies)\n",
    "#             indicies100 = indicies[0:batch_size]\n",
    "#             batch_xs = [data_for_training[j] for j in indicies100]\n",
    "#             batch_ys = [a_train[j] for j in indicies100]\n",
    "#             _, loss_value = sess.run([train_op, loss],\n",
    "#                              feed_dict={input_placeholder: batch_xs, labels_placeholder: batch_ys})\n",
    "#             if(i%500 == 0):\n",
    "#                 print(\"Alive and well! {} Loss: {:.2f}\".format(i, loss_value))\n",
    "#                 saver.save(sess, 'C:\\\\Users\\\\Brittany\\\\Dropbox\\\\School\\\\CMSC678\\\\machine-learning\\\\saved_models\\\\first_model',global_step=i+8500)\n",
    "                \n",
    "#         print(\"TRAINED!\")\n",
    "        \n",
    "#         # Calculate accuracy\n",
    "#         print(p_out.shape())\n",
    "#         accuracy = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones(tf.stack([tf.shape(p_out)[0], 1])))), tf.log(tf.add(labels_placeholder, tf.ones(tf.stack([tf.shape(labels_placeholder)[0], 1]))))))))\n",
    "#         return accuracy.eval({input_placeholder: data_for_testing, labels_placeholder: a_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25 features\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\first_model-8500\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key Variable_9 not found in checkpoint\n\t [[Node: save_3/RestoreV2_27 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_3/Const_0_0, save_3/RestoreV2_27/tensor_names, save_3/RestoreV2_27/shape_and_slices)]]\n\nCaused by op 'save_3/RestoreV2_27', defined at:\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-c46f359fd9fa>\", line 1, in <module>\n    accResults_retry = getNeuralNetAndContinueRunning(train_data, train_labels, test_data, test_labels)\n  File \"<ipython-input-14-e711ef4f7eb0>\", line 37, in getNeuralNetAndContinueRunning\n    saver = tf.train.Saver()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1218, in __init__\n    self.build()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1020, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key Variable_9 not found in checkpoint\n\t [[Node: save_3/RestoreV2_27 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_3/Const_0_0, save_3/RestoreV2_27/tensor_names, save_3/RestoreV2_27/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key Variable_9 not found in checkpoint\n\t [[Node: save_3/RestoreV2_27 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_3/Const_0_0, save_3/RestoreV2_27/tensor_names, save_3/RestoreV2_27/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c46f359fd9fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccResults_retry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetNeuralNetAndContinueRunning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-e711ef4f7eb0>\u001b[0m in \u001b[0;36mgetNeuralNetAndContinueRunning\u001b[1;34m(data_for_training, a_train, data_for_testing, a_test)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C:\\\\Users\\\\Brittany\\\\Dropbox\\\\School\\\\CMSC678\\\\machine-learning\\\\saved_models\\\\first_model-8500\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1666\u001b[1;33m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1667\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key Variable_9 not found in checkpoint\n\t [[Node: save_3/RestoreV2_27 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_3/Const_0_0, save_3/RestoreV2_27/tensor_names, save_3/RestoreV2_27/shape_and_slices)]]\n\nCaused by op 'save_3/RestoreV2_27', defined at:\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-c46f359fd9fa>\", line 1, in <module>\n    accResults_retry = getNeuralNetAndContinueRunning(train_data, train_labels, test_data, test_labels)\n  File \"<ipython-input-14-e711ef4f7eb0>\", line 37, in getNeuralNetAndContinueRunning\n    saver = tf.train.Saver()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1218, in __init__\n    self.build()\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1020, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Brittany\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key Variable_9 not found in checkpoint\n\t [[Node: save_3/RestoreV2_27 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_3/Const_0_0, save_3/RestoreV2_27/tensor_names, save_3/RestoreV2_27/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "# accResults_retry = getNeuralNetAndContinueRunning(train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(accResults_retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildNeuralNetAndGetAccuracy2(data_for_training, a_train, data_for_testing, a_test):\n",
    "    #Only two layers\n",
    "    batch_size = 300\n",
    "    iterations = 10000\n",
    "    \n",
    "    inputFeatureSize = len(data_for_training[0])\n",
    "    print(\"There are {} features\".format(inputFeatureSize))\n",
    "    hidden_units1 = 25\n",
    "    hidden_units2 = 25\n",
    "    output_size = 1\n",
    "            \n",
    "    input_placeholder = tf.placeholder(tf.float32, shape=(None, inputFeatureSize), name = \"input_placeholder\")\n",
    "    labels_placeholder = tf.placeholder(tf.float32, shape=(None, 1), name = \"labels_placeholder\")\n",
    "    \n",
    "    #remember that we need W of small random values for gradient descent\n",
    "    hiddenLayer1W = tf.get_variable(\"w1\", initializer = tf.truncated_normal([inputFeatureSize, hidden_units1], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "    hiddenLayer2W = tf.get_variable(\"w2\", initializer = tf.truncated_normal(shape=(hidden_units1, hidden_units2), stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "    outW = tf.get_variable(\"outW\", initializer = tf.truncated_normal(shape=(hidden_units2, output_size), stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "\n",
    "    hiddenLayer1b = tf.get_variable(\"b1\", initializer = tf.truncated_normal([hidden_units1], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "    hiddenLayer2b = tf.get_variable(\"b2\", initializer = tf.truncated_normal([hidden_units2], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "    outb = tf.get_variable(\"outB\", initializer = tf.truncated_normal([output_size], stddev=1.0 / math.sqrt(float(inputFeatureSize))))\n",
    "\n",
    "    hiddenLayer1 = tf.nn.relu(tf.matmul(input_placeholder, hiddenLayer1W) + hiddenLayer1b)\n",
    "    hiddenLayer2 = tf.nn.relu(tf.matmul(hiddenLayer1, hiddenLayer2W) + hiddenLayer2b)\n",
    "    p_out = tf.matmul(hiddenLayer2, outW) + outb\n",
    "        \n",
    "#     loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones([len(p_out), 1]))), tf.log(tf.add(a_train, tf.ones([len(a_train), 1])))))))\n",
    "    loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones(tf.stack([tf.shape(p_out)[0], 1])))), tf.log(tf.add(labels_placeholder, tf.ones(tf.stack([tf.shape(labels_placeholder)[0], 1]))))))))\n",
    "\n",
    "    # Other optimizers - https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.25)\n",
    "    \n",
    "    global_step_counter = tf.get_variable(\"globalStepVal\", initializer = 0, trainable=False)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step_counter)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        for i in range(0,iterations):\n",
    "            indicies = list(range(0,len(data_for_training)))\n",
    "            shuffle(indicies)\n",
    "            indicies100 = indicies[0:batch_size]\n",
    "            batch_xs = [data_for_training[j] for j in indicies100]\n",
    "            batch_ys = [a_train[j] for j in indicies100]\n",
    "            _, loss_value = sess.run([train_op, loss],\n",
    "                             feed_dict={input_placeholder: batch_xs, labels_placeholder: batch_ys})\n",
    "            if(i%500 == 0):\n",
    "                print(\"Alive and well! {} Loss: {:.2f}\".format(i, loss_value))\n",
    "                saver.save(sess, 'C:\\\\Users\\\\Brittany\\\\Dropbox\\\\School\\\\CMSC678\\\\machine-learning\\\\saved_models\\\\relu_final\\\\model.ckpnt',global_step=i)\n",
    "                \n",
    "        print(\"TRAINED!\")\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones(tf.stack([tf.shape(p_out)[0], 1])))), tf.log(tf.add(labels_placeholder, tf.ones(tf.stack([tf.shape(labels_placeholder)[0], 1]))))))))\n",
    "        return accuracy.eval({input_placeholder: data_for_testing, labels_placeholder: a_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25 features\n",
      "Alive and well! 0 Loss: 4.50\n",
      "Alive and well! 500 Loss: 0.71\n",
      "Alive and well! 1000 Loss: 0.70\n",
      "Alive and well! 1500 Loss: 0.75\n",
      "Alive and well! 2000 Loss: 0.53\n",
      "Alive and well! 2500 Loss: 0.48\n",
      "Alive and well! 3000 Loss: 0.48\n",
      "Alive and well! 3500 Loss: 0.45\n",
      "Alive and well! 4000 Loss: 0.44\n",
      "Alive and well! 4500 Loss: 0.44\n",
      "Alive and well! 5000 Loss: 0.19\n",
      "Alive and well! 5500 Loss: 0.51\n",
      "Alive and well! 6000 Loss: 0.53\n",
      "Alive and well! 6500 Loss: 0.40\n",
      "Alive and well! 7000 Loss: 0.18\n",
      "Alive and well! 7500 Loss: 0.34\n",
      "Alive and well! 8000 Loss: 0.21\n",
      "Alive and well! 8500 Loss: 0.35\n",
      "Alive and well! 9000 Loss: 0.30\n",
      "Alive and well! 9500 Loss: 0.20\n",
      "TRAINED!\n"
     ]
    }
   ],
   "source": [
    "accResults2 = buildNeuralNetAndGetAccuracy2(train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(accResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reluGet(data_for_training, a_train, data_for_testing, a_test):\n",
    "    #Only two layers\n",
    "    batch_size = 300\n",
    "    \n",
    "    inputFeatureSize = len(data_for_training[0])\n",
    "    print(\"There are {} features\".format(inputFeatureSize))\n",
    "    hidden_units1 = 25\n",
    "    hidden_units2 = 25\n",
    "    output_size = 1\n",
    "            \n",
    "    input_placeholder = tf.placeholder(tf.float32, shape=(None, inputFeatureSize), name = \"input_placeholder\")\n",
    "    labels_placeholder = tf.placeholder(tf.float32, shape=(None, 1), name = \"labels_placeholder\")\n",
    "    \n",
    "    #remember that we need W of small random values for gradient descent\n",
    "    hiddenLayer1W = tf.get_variable(\"w1\", shape = [inputFeatureSize, hidden_units1])\n",
    "    hiddenLayer2W = tf.get_variable(\"w2\", shape = [hidden_units1, hidden_units2])\n",
    "    outW = tf.get_variable(\"outW\", shape = [hidden_units2, output_size])\n",
    "\n",
    "    hiddenLayer1b = tf.get_variable(\"b1\", shape=[hidden_units1])\n",
    "    hiddenLayer2b = tf.get_variable(\"b2\", shape=[hidden_units2])\n",
    "    outb = tf.get_variable(\"outB\", shape=[output_size])\n",
    "\n",
    "    hiddenLayer1 = tf.nn.relu(tf.matmul(input_placeholder, hiddenLayer1W) + hiddenLayer1b)\n",
    "    hiddenLayer2 = tf.nn.relu(tf.matmul(hiddenLayer1, hiddenLayer2W) + hiddenLayer2b)\n",
    "    p_out = tf.matmul(hiddenLayer2, outW) + outb\n",
    "        \n",
    "#     loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones([len(p_out), 1]))), tf.log(tf.add(a_train, tf.ones([len(a_train), 1])))))))\n",
    "    loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones(tf.stack([tf.shape(p_out)[0], 1])))), tf.log(tf.add(labels_placeholder, tf.ones(tf.stack([tf.shape(labels_placeholder)[0], 1]))))))))\n",
    "\n",
    "    # Other optimizers - https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.25)\n",
    "    \n",
    "    global_step_counter = tf.get_variable(\"globalStepVal\", initializer = 0, trainable=False)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step_counter)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "#         init = tf.global_variables_initializer()\n",
    "#         sess.run(init)\n",
    "        saver.restore(sess, \"C:\\\\Users\\\\Brittany\\\\Dropbox\\\\School\\\\CMSC678\\\\machine-learning\\\\saved_models\\\\relu_final\\\\model.ckpnt-9500\")\n",
    "\n",
    "#         for i in range(0,iterations):\n",
    "#             indicies = list(range(0,len(data_for_training)))\n",
    "#             shuffle(indicies)\n",
    "#             indicies100 = indicies[0:batch_size]\n",
    "#             batch_xs = [data_for_training[j] for j in indicies100]\n",
    "#             batch_ys = [a_train[j] for j in indicies100]\n",
    "#             _, loss_value = sess.run([train_op, loss],\n",
    "#                              feed_dict={input_placeholder: batch_xs, labels_placeholder: batch_ys})\n",
    "#             if(i%500 == 0):\n",
    "#                 print(\"Alive and well! {} Loss: {:.2f}\".format(i, loss_value))\n",
    "#                 saver.save(sess, 'C:\\\\Users\\\\Brittany\\\\Dropbox\\\\School\\\\CMSC678\\\\machine-learning\\\\saved_models\\\\relu_basic\\\\model.ckpnt',global_step=i)\n",
    "                \n",
    "        print(\"TRAINED!\")\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(tf.add(p_out, tf.ones(tf.stack([tf.shape(p_out)[0], 1])))), tf.log(tf.add(labels_placeholder, tf.ones(tf.stack([tf.shape(labels_placeholder)[0], 1]))))))))\n",
    "        return accuracy.eval({input_placeholder: data_for_testing, labels_placeholder: a_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25 features\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\relu_final\\model.ckpnt-9500\n",
      "TRAINED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31804609"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reluGet(train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25 features\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brittany\\Dropbox\\School\\CMSC678\\machine-learning\\saved_models\\relu_final\\model.ckpnt-9500\n",
      "TRAINED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31798878"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "march_data = pd.read_pickle(\"data/allMarchEnriched\")\n",
    "march_test, march_labels = cleanData(march_data, try_with_minutes)\n",
    "\n",
    "reluGet(train_data, train_labels, march_test, march_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
